---
title: "Lesson 6"
subtitle: "Introduction to probability and random variables"
author: "JMG"
format:
  html:
    echo: true
    code-fold: false
    code-summary: "Show the code"
    toc: true
    toc-location: left
bibliography: lesson06.bib
license: "CC BY-NC-SA 4.0"
---



## Learning Objectives

After this lesson, students will be able to: 

- Identify and describe some common probability distributions. 

- State Bayes' theorem.

- Understand the concepts of probability mass functions (PMFs), probability density functions (PDFs), and cumulative distribution functions (CDFs).

- Work with various distributions in R. 


## Overview

Probability and random variables play a fundamental role in data science and machine learning by providing the theoretical foundation for understanding uncertainty and variability in data. Later in the course, we will study inference and predictive modeling and it will be helpful to have the basic vocabulary of probability and random variables at our disposal to help describe methods for inference and predictive modeling.

Informally:

* **Probability** is the mathematical framework for quantifying uncertainty. In data science, it allows us to express how likely different outcomes are, providing a way to model the inherent variability in data. Probability is used to formulate hypotheses, make predictions, and assess the likelihood of various events occurring. Understanding probability is crucial when dealing with tasks such as statistical inference, hypothesis testing, machine learning, and Bayesian modeling.

* **Random variables** are a key concept that extends the idea of probability. A random variable is a variable whose value is subject to chance or randomness. In data science and machine learning, random variables are used to represent uncertain quantities that we wish to analyze. They can be discrete, like the outcome of a coin toss, or continuous, like the height of individuals in a population. Random variables help us describe and model data, and they serve as the basis for statistical models and machine learning algorithms.

There are other data science and mathematics courses in our curriculum that go into more detail on probability and random variables so our treatment in this course will be brief and informal.  

## Introduction to Probability

The notion of probability starts with the concept of a **random experiment**, that is, a process with a well-defined but unpredictable outcome. A quintessential example is provided by tossing a coin. We know in advance that the outcome will be either heads or tails but it is difficult to determine with certainty the outcome of any given toss. 

A working definition for probability that is often used is

> For an observation of a random phenomenon, the probability of a particular outcome is the proportion of times that outcome would occur in an indefinitely long sequence of like observations, under the same conditions. 

This definition is why one typically says that the probability of tossing heads for a fair coin is 0.5 (or 50%).

**Note:** According to our working definition a probability is always a number between 0 and 1 (inclusive).

For a random experiment, we define the **sample space**, often denoted by $S$ to he the set of all possible outcomes. So, the sample space for the random experiment of tossing a coin one time would be $S = \{\text{heads},\text{tails}\}$. An **event** is a subset of a sample space. We usually denote events by upper case latin letters like $A$. For example, the event of tossing a heads would be $A = \{\text{heads}\}$. 

While it takes some time and effort to wrap ones head around this, it is a fact that we can build up complicated events through logical operations. For example, we can define an event that is the event of tossing either heads or[^1] tails. Also, one can define an event that is the event of tossing heads and tails. 

[^1]: Here, "or" is used in the **inclusive** sense. 

**Question:** Suppose that $A$ is the event of tossing either heads or tails in a single toss of a coin. Why should we say that the probability of this event is 1? Suppose that  $B$ is the event of tossing both heads and tails in a single toss of a coin. Why should we say that the probability of this event is 0?

**Notation:** If $A$ is an event, we denote by $P(A)$ the probability that $A$ has occurred. Given two events $A$ and $B$, we denote by $A \cup B$ the event that $A$ or $B$ occurred; we denote by $A \cap B$ the event that $A$ and $B$ occurred. 

A notion from probability that is very important in data science is that of **conditional probability**. A probability of an event $A$, given that an event $B$ occurred, is called a conditional probability and is denoted by $P(A | B)$ and read as "the probability of $A$ given $B$". We define conditional probability mathematically by

$$
P(A | B) = \frac{P(A \cap B)}{P(B)}
$$

It is important to realize that in general $P(A|B) \neq P(B|A)$. For example, suppose that $A$ is the event that I carry an umbrella on any given day and $B$ is the event that it is raining on a given day. Then,

$$
P(A|B) = \text{the probability I will carry an umbrella given that it is raining}
$$

while

$$
P(B|A) = \text{the probability it is raining given that I'm carrying an umbrella}
$$

and there is no reason to believe that these probabilities should be the same. 

However, there is an important connection between $P(A|B)$ and  $P(B|A)$ known as **Bayes' theorem** which we state as

$$
P(B|A) = \frac{P(A|B)P(B)}{P(A)} = \frac{P(A|B)P(B)}{P(A|B)P(B) + P(A|B^{C})P(B^{C})}
$$
whenever $A$ is an event such that $P(A) \neq 0$ and where $B^{C}$ denotes the *complement* of the event $B$.

## Introduction to Random Variables 




## Preparation for the next lesson

To prepare for the next lesson, please read:

- [Chapter 5](https://datasciencebook.ca/classification1.html) on classification and [Chapter 7](https://datasciencebook.ca/regression1.html) on regression from [Data Science A First Introduction](https://datasciencebook.ca/preface.html) [@timbers2022data].


## References

::: {#refs}
:::


:::{.callout-tip collapse="true"}
## Expand for Session Info
```{r}
#| echo: false


library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```

:::


[![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1){fig-align="left" width=15%}](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode)


