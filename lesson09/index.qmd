---
title: "Lesson 9"
subtitle: "Introduction to Statistics for Data Science"
author: "JMG"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    toc: true
    toc-location: left
bibliography: lesson09.bib
license: "CC BY-NC-SA 4.0"
---

```{r}
#| message: false
#| warning: false
#| echo: false

# load packages used in document
library(tidyverse)
library(tidymodels)
library(kableExtra)

theme_set(theme_minimal(base_size = 13))

tidymodels_prefer()
```

## Learning Objectives

After this lesson, students will be able to:

- Describe real-world examples of questions that can be answered with statistical inference.

- Define common population parameters (e.g., mean, proportion, standard deviation) that are often estimated using sampled data, and estimate these from a sample.

- Define the following statistical sampling terms: population, sample, population parameter, point estimate, and sampling distribution.

- Define bootstrapping.

- Use R to create a bootstrap distribution to approximate a sampling distribution.

## Readings, etc.

1) Read Chapter 10 from from [Data Science: A First Introduction](https://datasciencebook.ca/preface.html) [@timbers2022data]. [View book online](https://datasciencebook.ca/preface.html).

2) You might also want to look at chapters 8 & 9 from [Statistical Inference via Data Science](https://moderndive.com/).



## Overview

Statistical inference is the process of using data analysis to infer properties of an underlying probability distribution. Inferential statistical analysis infers properties of a population, for example by testing hypotheses and deriving estimates. It is assumed that the observed data set is sampled from a larger population. Inferential statistics can be contrasted with descriptive statistics. Descriptive statistics is solely concerned with properties of the observed data, and it does not rest on the assumption that the data come from a larger population. 

In this lesson, we will get a feel for the inferential method. There are many details of statistics that we will leave for a later course. Further, our approach will be computational, utilizing the [bootstrap](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) resampling method.


## Motivating Example

Random variables and their distributions model processes that produce data. For example, a binomial random variable with probability of success $\pi = 0.5$ can be used to model the process of tossing a coin and observing the number of heads. This is an illustration of the domain of probability. 

Statistical inference is concerned with the inverse problem: given data, what can we say about the process that produced it? For example, given a sample of coin tosses, what can we say about the probability of heads? This is an illustration of the domain of statistics.

**Question:** Given a coin, how can you determine if it is fair or not? Think about how you could approach answering this question. 

Obviously, to address the previous question we should collect data. That is, we should toss the coin some number of times (probably very many)  and record the number of heads. Then, we can use the data to estimate the probability of heads.

**Question:** Suppose that we toss a coin 10 times and observe 7 heads. What is your best guess for the probability of heads? Suppose that we toss a coin 100 times and observe 70 heads. What is your best guess for the probability of heads?

At this point, there are a few things to take note of:

1. When we do statistical inference, we are often trying to estimate a parameter(s) of a distribution. The parameter(s) should be viewed as fixed but with unknown values. In this case, we call the parameter or parameters a **population parameter**. In the coin example, the population parameter is the probability of heads, $\pi$.  

2. We have some process to estimate the population parameter. This process inputs observed data and returns an estimated value for the parameter(s). In this case, we call the estimate a **point estimate**. In the coin example, the point estimate is the number of heads divided by the number of tosses, we denote this by $\hat{\pi}$.

3. The point estimate is a random variable. That is, if we were to repeat the experiment, we would get a different point estimate. This is because the observed data is random. In this case, we call the point estimate a **statistic**. In the coin example, the statistic is the number of heads divided by the number of tosses, that is, $\hat{\pi}$.

4. Since the point estimate is a random variable, it has a distribution. In this case, we call the distribution a **sampling distribution**. In the coin example, the sampling distribution is the distribution of $\hat{\pi}$. 

5. A key problem in statistical inference is to determine or describe the sampling distribution of a statistic. For example, we might be interested to know what is the mean and variance of the sampling distribution. The standard deviation of the sampling distribution of a statistic is called the **standard error**. We call the process of determining the sampling distribution **statistical inference**. In the coin example, we want to determine the sampling distribution of $\hat{\pi}$.

6. One can use the sampling distribution of a statistic to make statements about the uncertainty of point estimates. 
  

In mathematical statistics, there is a heavy focus on deriving closed form or asymptotically exact expressions for the sampling distribution of a statistic. This is amazing and beautiful and well worth learning. For this, we highly recommend [@wasserman2004all] or the online book [Introduction to Probability for Data Science](https://probability4datascience.com/). However, this approach is beyond the scope of this course. Further, the precise formulas of mathematical statistics apply in a much too limited range of application for the purposes of modern data science.   

As an alternative to mathematical statistics, one can take a computational approach. That is, use the computer to simulate the sampling distribution of a statistic. This approach is called **bootstrapping**. The bootstrap is a powerful tool that can be used to approximate the sampling distribution of a statistic. It is also a useful tool for hypothesis testing and obtaining confidence intervals. Even our coverage of the bootstrap will be only introductory. To learn more beyond what we cover, we recommend [@efron2022computer].

## Resampling Experiment

Let's start with a simulation. Here's what we will do: Simulate 100 tosses of a fair coin, that is, sample from a binomial random variable with $\pi = 0.5$, count the number of heads, then estimate $\pi$ by dividing the number of heads by 100. Then, we will repeat this for 500 times. The code below does this and displays the results in a table. 

```{r}
set.seed(1234)
coin_df <- tibble(num_heads = rbinom(500,size=100,prob=0.5))

coin_df <- coin_df %>%
  mutate(p_hat = num_heads/100)

coin_df %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "200px")

```


@fig-coin-plot plots the 500 different estimates for $\pi$.

```{r}
#| label: fig-coin-plot 
#| fig-cap: 500 estimates of the probability of success, $\pi$ from simulated data.
coin_df %>%
  ggplot(aes(x = p_hat)) +
  geom_histogram(bins = 12,color="white") + 
  labs(x = "Estimate",y = "Count") 
```


**Question:** What are your takeaways from our simulation experiment and plot in @fig-coin-plot? What, if anything, do you think we can say about the sampling distribution of $\pi$?

Now, let's try a slightly different simulation. We will do a single round of tossing a fair coin 100 times. Then, we will resample from the 100 tosses *with replacement* 500 times. For each resample, we will count the number of heads and again estimate $\pi$ by dividing the number of heads by 100. The code in below does this and displays the results in a table. 

```{r}    
set.seed(1234)
coin_sample <- rbinom(100,size=1,prob=0.5)

coin_resample_df <- tibble(num_heads = replicate(500,sum(sample(coin_sample,100,replace=TRUE)))) %>%
  mutate(p_hat_b = num_heads/100)


coin_resample_df %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "200px")
```


Note the the number of heads in the original sample is `r sum(coin_sample)`. 

@fig-coin-resample-plot plots the 500 different estimates for $\pi$ based on the *resampled* data.

```{r}
#| label: fig-coin-resample-plot
#| fig-cap: 500 estimates of the probability of success, $\pi$ from resampled data.

coin_resample_df %>%
  ggplot(aes(x = p_hat_b)) +
  geom_histogram(bins = 12,color="white") + 
  labs(x = "Estimate",y = "Count") 

```


**Question:** What are your takeaways from our simulation experiment and plot in @fig-coin-resample-plot? How do the results compare and contrast with those of the previous simulation and plot in @fig-coin-plot? 

## Bootstrap

Our resampling simulation in the last section is an example of the **bootstrap**. Notice what we did, we took a sample from the population, then resampled from the sample. This is called **resampling**. The bootstrap is a special case of resampling where the resampling is done with replacement. What we did was generate a bootstrap distribution for our statistic. The idea is, 

> if the sample is representative of the population, then the bootstrap distribution of our statistics obtained by resampling with replacement from the sample should approximate the sampling distribution for our statistic.

While the mean of the bootstrap will be the mean of the sample and not necessarily the mean of the population, the standard deviation of the bootstrap will be a good estimate for the standard error of the statistic. Thus, the bootstrap distribution allows us to assess the uncertainty of an estimate. The power of the bootstrap technique is that it works for any statistic. For example, we can use the bootstrap to estimate the sampling distribution for the mean for a normal random variable, or parameters in models such as the coefficients in a linear regression model. We can even use the bootstrap to estimate the uncertainty in model predictions, even if the model is non-parametric.  

### Example: Bootstrap Mean

Let's take $n = 50$ samples $X_{1},X_{2},\ldots, X_{n}$ from a normal distribution with $\mu = 10$ and $\sigma = 1.75$, that is, with $X_{i} \sim \text{Norm}(\mu = 10, \sigma = 1.75 )$:

```{r}
#| code-fold: false

set.seed(4321)
n <- 50
mu <- 10
sigma <- 1.75
x <- rnorm(n,mu,sigma)
```

A point estimate for the mean $\mu$ is the sample mean $\hat{\mu}$ defined by

$$
\hat{\mu} = \frac{X_{1} + X_{2} + \cdots + X_{n}}{n}
$$
Let's compute the sample mean for our sample:

```{r}
#| code-fold: false


(x_bar <- mean(x))
```

Now, let's build the bootstrap distribution for the sample mean. We will do this by resampling with replacement from the sample 500 times. For each resample, we will compute the sample mean. The code below does this and displays the results. 

```{r}
#| code-fold: false


mean_resample_df <- tibble(x_bar_b = replicate(500,mean(sample(x,n,replace=TRUE)))) 

mean_resample_df %>%
  ggplot(aes(x = x_bar_b)) +
  geom_histogram(bins = 12,color="white") + 
  labs(x = "Sample mean",y = "Count") 
```

Now, statistical theory tell us that the standard error of the sample mean is given by

$$
\text{SE}(\hat{\mu}) = \frac{\sigma}{\sqrt{n}}
$$
where $\sigma$ is the standard deviation of the population. Let's compute the standard error of the sample mean for our sample:

```{r}
#| code-fold: false


(se <- sigma/sqrt(n))
```

Let's compare this with the standard deviation of our bootstrap distribution:

```{r}
#| code-fold: false


sd(mean_resample_df$x_bar_b)
```

We use confidence intervals (CIs) to quantify the uncertainty in our estimates. Classically, a 95% CI for the mean is computed in R using:

```{r}
#| code-fold: false


t.test(x)$conf.int
```

or using a function from the `infer` package:

```{r}
#| code-fold: false


sampling_dist <- tibble(x=x) %>%
  specify(response = x) %>%
  assume("t")

sample_mean <- tibble(x=x) %>%
  specify(response = x) %>%
  calculate(stat = "mean")

get_confidence_interval(sampling_dist,point_estimate = sample_mean,level=0.95,type="se")
```

We can estimate this CI using the bootstrap. The code below computes an estimated 95% CI for the mean using the bootstrap:

```{r}
#| code-fold: false


quantile(mean_resample_df$x_bar_b,probs = c(0.025,0.975))

```

or using the `infer` package:

```{r}
#| code-fold: false


mean_resample_df %>%
  get_confidence_interval(level=0.95)
  

```

**Exercise:** Redo what we have done in bootstrapping the mean of a sample from a normal distribution but instead bootstrap the median and estimate the standard error and a 95% CI for the statistic. You can use the fact that the function `median` computes the sample median. How do the results compare and contrast with those of the mean?


### Example: Linear Regression

Let's suppose that we have samples from a normal distribution but where the mean varies as a linear function of a variable $x$. That is, we have samples from a distribution $\text{Norm}(\beta_{0} + \beta_{1}x, \sigma)$, where $x$ ranges over some values. This is equivalent to assuming that we have a random variable $Y$ that satisfies

$$
Y = \beta_{0} + \beta_{1}x + \epsilon
$$
and $\epsilon \sim \text{Norm}(0,\sigma)$. 

We can use the bootstrap to estimate the uncertainty in estimates for the parameters $\beta_{0}$ and $\beta_{1}$ in a manner similar to how we estimated the uncertainty in the sample mean in the last subsection. However, in this case, the mean is estimated by a linear regression model. That is, we have estimators $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$, values of which are obtained by fitting a linear model to the data. Bootstrapping allows us to approximate the sampling distributions for these estimators.

First, we will simulate some data. The simulated data is shown in @fig-lm-sim. Notice that the true mean is given by $y = 0.5 x + 2$ which appears as the red dashed line in the figure.

```{r}
#| code-fold: false
#| message: false
#| label: fig-lm-sim
#| fig-cap: Simulated data for simple linear regression. The true mean is given by $y = 0.5 x + 2$ 

# sample size
N <- 25

# true intercept and slope parameters
beta_0 <- 2
beta_1 <- 0.5

# x-values
x <- seq(0, 3, length.out = N)

# data simulation
lm_samp <- function(x,samp_n=10,sd_val=1){
  
  # sample from a normal distribution with mean = beta_0 + beta_1*x
  y <- rnorm(samp_n, mean=beta_0 + beta_1*x, sd=sd_val)
  
  tibble(x=x,y=list(y))
  
}

# obtain simulated data
lm_samp_df <- map_dfr(x,lm_samp)

lm_samp_df_l <- lm_samp_df %>%
  unnest(y)

# plot simulated data
lm_samp_df_l %>%
  ggplot(aes(x=x,y=y)) +
  geom_point(alpha=0.6) +
  geom_abline(intercept=beta_0,slope=beta_1,color="red",
              linewidth=1,linetype="dashed") + 
  geom_smooth(method="lm",color="orange",fill="lightblue")
```


The orange line in @fig-lm-sim is the fitted linear model and the light blue shaded region shows the corresponding standard error computed by traditional methods.

In R, the function `lm` is used to fit a linear model. The code below fits a linear model to the simulated data and prints the estimated intercept and slope parameters, that is, the point estimates for $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ in @tbl-lm-coeffs.

```{r}
#| code-fold: false
#| message: false
#| label: tbl-lm-coeffs
#| tbl-cap: Estimated intercept and slope parameters for the linear model fit to the simulated data.

linear_mod <- lm(y ~ x, data=lm_samp_df_l)

tidy(linear_mod) %>%
  select(estimate) %>%
  mutate(coeff=c("beta_0","beta_1")) %>%
  kable() %>%
  kable_styling()
```


We would like to assess the  uncertainty in our point estimates. Bootstrapping is one way to do this and the following code implements the bootstrap for our example. @fig-lm-boot-coeffs-1 shows the bootstrap distribution for the intercept and slope parameters. 


```{r}
#| code-fold: false
#| message: false
#| label: fig-lm-boot-coeffs-1
#| fig-cap: Bootstrap distributions for the intercept and slope parameters.

lm_fit_resamp <- function(int_val,df=lm_samp_df_l){
  lm(y ~ x, data=slice_sample(df,prop=1,replace=TRUE)) %>%
    tidy() %>%
    select(estimate) %>%
    mutate(coeff=c("beta_0","beta_1"))
}


lm_fit_boot <- map_dfr(1:500,lm_fit_resamp)

lm_fit_boot %>%
  ggplot(aes(x=estimate)) +
  geom_histogram(color="white",fill="lightblue") +
  facet_wrap(~coeff,scales="free_x")
```


In the last line of code, we manually resampled the data and fit a linear model to each resample. The code below does the same thing but uses the function `reg_intervals` from the `rsample`` package to do the resampling and fitting. The results shown in @fig-lm-boot-coeffs-2 are similar to those we saw in @fig-lm-boot-coeffs-1.

```{r}
#| code-fold: false
#| message: false
#| label: fig-lm-boot-coeffs-2
#| fig-cap: Bootstrap distributions for the intercept and slope parameters. This time, the function `reg_intervals` is used to do the resampling and fitting.

reg_intervals(y ~ x, data=lm_samp_df_l,
              type="percentile",filter=NULL,
              keep_reps = TRUE) %>%
  unnest(.replicates) %>%
  ggplot(aes(x=estimate)) + 
  geom_histogram(color="white",fill="lightblue") +
  facet_wrap(~term,scales="free_x")
```


We can also use `reg_intervals` to obtain the confidence intervals for each parameter estimate. The results are shown in 

```{r}
#| code-fold: false
#| label: tbl-lm-ci
#| tbl-cap: Confidence intervals for the intercept and slope parameters obtained using the `reg_intervals` function.


reg_intervals(y ~ x, data=lm_samp_df_l,
              type="percentile",filter=NULL) %>%
  kable() %>%
  kable_styling()
```

Finally, we can use our bootstrapped estimates to plot the bootstrap distribution of the regression line. The results are shown in @fig-lm-boot. The orange line is the fitted linear model, the yellow shaded region shows the corresponding standard error computed by traditional methods,  and the light blue lines are regression lines fitted to the resampled data. The light blue lines are the bootstrap distribution of the regression line. 

```{r}
#| code-fold: false
#| message: false
#| warning: false
#| label: fig-lm-boot
#| fig-cap: Bootstrap distribution of the regression line for the simulated data. The true value is given by $y = 0.5 x + 2$

tpl <- lm_fit_boot %>% pivot_wider(names_from=coeff,values_from=estimate) %>%
  unnest(cols = c(beta_0, beta_1))


lm_samp_df_l %>%
  ggplot(aes(x=x,y=y)) +
  geom_point(alpha=0.6) +
  geom_abline(data=tpl,
              aes(intercept=beta_0,slope=beta_1),
              color="lightblue") +
  geom_smooth(method="lm",color="orange",fill="yellow") 
```


Now that you have a background in the general idea of statistical inference and the approach we will take to inference using the bootstrap, let's work together in an RStudio project to apply our knowledge to actual data science problems.

## References

::: {#refs}
:::

::: {.callout-tip collapse="true"}
## Expand for Session Info

```{r}
#| echo: false


library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```
:::

[![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1){fig-align="left" width="15%"}](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode)


